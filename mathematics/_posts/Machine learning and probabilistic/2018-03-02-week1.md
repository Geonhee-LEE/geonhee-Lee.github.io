---
layout: post
title:  "Machine leaning"
categories: machine_learning
tags: 
comments: true
---

# Week1 - Motivation and Basics

### Table of Contents
{:.no_toc}
0. this unordered seed list will be replaced by toc as unordered list
{:toc}

-------------


- Weekly Objectives
  - Motivate the study on
    - Machinelearning,AI,Datamining....
    - Why? What?
    - Overview of the field
  - Short questions and answers on a story
    - What consists of machine learning?
    - MLE
    - MAP
  - Some basics
    - Probability
    - Distribution
    - And some rules...

-------------

### Binomial Distribution

- Binomialdistributionis
  - The __discrete probability distribution__
  - Of the number of successes in a sequence of __n independent yes/no experiments__, and each success has the probability of __$$\theta$$__
  - Also called a Bernoull iexperiment
- Flips are __i.i.d__
  - Independent events (처음 던질 때와 두 번째 던질 때 연관이 없는 상태)
  - Identically distributed according to binomial distribution (던질때마다 동일한 확률 분포를 가질 때)
- P(H) = $$\theta$$, P(T)=1 - $$\theta$$
- P(HHTHT)= $$\theta \cdot \theta  \cdot  (1- \theta)  \cdot  \theta  \cdot  (1- \theta) = \theta ^3(1 - \theta)^2$$
- Let's say
  - D as Data = H, H, T, H, T
    - n = 5
    - k = $$a_H$$ =3
    - p = $$\theta$$
  - p(D|$$\theta$$) = $$\theta ^{a_H} (1-\theta)^{a_T}$$

> How to get the probability?
  
### Maximum Likelihood Estimation

-  p(D|$$\theta$$) = $$\theta ^{a_H} (1-\theta)^{a_T}$$ 
   -  Data: We have obseved the sequence data of D with $$a_H$$ and $$a_T$$
-  Our hypothesis:
   -  The gambiling result follows the binomial distribution of $$\theta$$
-  How to make our hypothesis strong(어떻게 '참'이다라고 말할 수 있을까)?
   -  Finding out a better distribution of the observation
      -  Can be done, but you need more rational.
      -  Binomial distribution보다 좋은 hypothesis 구조가 있다면, 이것도 가능하지만 더 많은 합리적 생각이 필요.
   -  Finding out the best candidate of $$\theta$$
      -  What's the condition to __make $$\theta$$ most plausible__ ?
      -  $$\theta$$를 최적화하여 hypothesis를 strong하게 만들 수 있음.

어떤 $$\theta$$를 선택했을 때 data를 가장 잘 설명할 수 있을까? 

- One candidate is the __Maximum Likelihood Estimation (MLE) of $$\theta$$
  - Choose $$\theta$$ that maximized the probability of obseverd data

$$
\begin{aligned}
\hat{\theta} = argmax_\theta P(D| \theta)
\end{aligned} 
$$


### MLE calculation

- $$\hat{\theta} = argmax_\theta P(D| \theta) = argmax_\theta \theta ^{a_H} (1-\theta)^{a_T}$$
- This is going nowhere, so you use a trick (자승을 처리하기 까다로움)
  - Using the __log function__.
- $$\hat{\theta} = argmax_\theta ln P(D| \theta) = argmax_\theta ln{\theta ^{a_H} (1-\theta)^{a_T}} = argmax_\theta { a_H ln\theta + a_T ln (1-\theta)} }$$








<figure>
  <img alt="An image with a caption" src="/assets/img/Robot_dynamics/1.png" class="lead" data-width="240" data-height="180" />
</figure>

------------

> Reference:
- [KAIST - Industrial & Systems Engineering Dept](https://aai.kaist.ac.kr/xe2/)
- [기계 학습, Machine Learning, AAILAB KAIST](https://www.youtube.com/playlist?list=PLbhbGI_ppZISMV4tAWHlytBqNq1-lb8bz)